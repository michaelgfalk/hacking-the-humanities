{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":84369408},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"type":"settings"}
{"cell_type":"code","exec_count":1,"id":"4a36e9","input":"import nltk\nnltk.download('popular')","output":{"0":{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading collection 'popular'\n[nltk_data]    | \n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/cmudict.zip.\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/genesis.zip.\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/inaugural.zip.\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n[nltk_data]    | Downloading package names to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/names.zip.\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/stopwords.zip.\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/treebank.zip.\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n[nltk_data]    | Downloading package omw to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/omw.zip.\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/wordnet.zip.\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n[nltk_data]    | Downloading package words to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping corpora/words.zip.\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n[nltk_data]    | Downloading package punkt to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /Users/michaelgfalk/nltk_data...\n[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n[nltk_data]    | \n[nltk_data]  Done downloading collection popular\n"},"1":{"data":{"text/plain":"True"},"exec_count":1,"output_type":"execute_result"}},"pos":1,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"4f4956","input":"pandavas[1]","output":{"0":{"data":{"text/plain":"{'name': 'Bhima',\n 'gender': 'M',\n 'species': 'demigod',\n 'family': 'Pandavas',\n 'profession': 'mace wielder',\n 'spouse': 'Draupadi'}"},"exec_count":13,"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"6ef3a6","input":"# YOUR CODE HERE\nsecond_name = pandavas[1]['name']\nsecond_spouse = pandavas[1]['spouse']\n\nfifth_name = pandavas[4]['name']\nfifth_spouse = pandavas[4]['spouse']\n\nnum_pandavas = len(pandavas)\n# END OF YOUR CODE\n\nprint(f'The second-eldest Pandava was {second_name}. He was married to {second_spouse}.')\nprint(f'The fifth Pandava was {fifth_name}. He was married to {fifth_spouse}.')\nprint(f'There were {num_pandavas} Pandava brothers.')","output":{"0":{"name":"stdout","output_type":"stream","text":"The second-eldest Pandava was Bhima. He was married to Draupadi.\nThe fifth Pandava was Sahadeva. He was married to Draupadi.\nThere were 6 Pandava brothers.\n"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"ee6589","input":"my_list = [7, 12, 84, 6, 0]\n\nfor number in my_list:\n    new_number = number + 2\n    print(f\"The new number is {new_number}.\")","output":{"0":{"name":"stdout","output_type":"stream","text":"The new number is 9.\nThe new number is 14.\nThe new number is 86.\nThe new number is 8.\nThe new number is 2.\n"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"4804fe","input":"upper_case_list = ['THE','CAT','SAT','ON','THE','MAT']\n\n# YOUR CODE HERE:\nfor arbitrary_name in upper_case_list :\n    new_word = arbitrary_name.lower()\n    \n# END OF YOUR CODE\n    print(f'The new word is {new_word}.')","output":{"0":{"name":"stdout","output_type":"stream","text":"The new word is the.\nThe new word is cat.\nThe new word is sat.\nThe new word is on.\nThe new word is the.\nThe new word is mat.\n"}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"b73824","input":"number_list = [54,77,23,4,90,81]\n\n# YOUR CODE HERE:\nempty_list = []\n\n# Loop over the list of numbers:\nfor number in number_list :\n    # Calculate the new number:\n    new_number = number * 3\n    # Append it to the empty list:\n    empty_list.append(new_number)\n\n# END OF YOUR CODE\n    print(f'New number apppended! The empty_list is now: {empty_list}.')","output":{"0":{"name":"stdout","output_type":"stream","text":"New number apppended! The empty_list is now: [162].\nNew number apppended! The empty_list is now: [162, 231].\nNew number apppended! The empty_list is now: [162, 231, 69].\nNew number apppended! The empty_list is now: [162, 231, 69, 12].\nNew number apppended! The empty_list is now: [162, 231, 69, 12, 270].\nNew number apppended! The empty_list is now: [162, 231, 69, 12, 270, 243].\n"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"1dc1ff","input":"my_list = [7, 8, 9]\nprint(my_list[1])","output":{"0":{"name":"stdout","output_type":"stream","text":"8\n"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"9bebaa","input":"import os\nfile_list = os.listdir('corpus') # get list of filenames in 'corpus' folder\nfile_list # print the list","output":{"0":{"data":{"text/plain":"['erewhon.txt',\n 'moby_dick.txt',\n 'gitanjali.txt',\n 'corinne.txt',\n 'pilgrims_progress.txt',\n 'pride_and_prejudice.txt',\n 'father_goriot.txt',\n 'north_and_south.txt',\n 'such_is_life.txt',\n 'jane_eyre.txt']"},"exec_count":20,"output_type":"execute_result"}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"b37116","input":"# YOUR CODE HERE:\n\n# First create the empty list to store your corpus:\nnovel_list = []\n\n# Now loop over 'file_list':\nfor file_name in file_list :\n    # Create a new dict for the current novel in the list (done for you)\n    current_novel = {}\n    \n    # Set the title to be the file name \n    current_novel['title'] = file_name\n    \n    # Now open the file of the novel.\n    # First add 'corpus/' to the file name, so that Python knows where to find the file:\n    file_path = 'corpus/' + file_name\n    \n    # Then open the file and read it:\n    with open(file_path, encoding='utf-8', mode='r', errors='ignore') as novel_file:\n        # Now the file is open, use the '.read()' method to get the text\n        current_novel['text'] = novel_file.read()\n    # Finally, append the current novel to the novel_list:\n    novel_list.append(current_novel)\n    \n# END OF YOUR CODE\n\nprint(f'Corpus imported. There are {len(novel_list)} novels in the corpus.\\n')\nprint(f'The third novel is {novel_list[2][\"title\"]}. The first 200 characters are:\\n\\n {novel_list[2][\"text\"][0:200]}...')","output":{"0":{"name":"stdout","output_type":"stream","text":"Corpus imported. There are 10 novels in the corpus.\n\nThe third novel is gitanjali.txt. The first 200 characters are:\n\n ***ï»¿The Project Gutenberg EBook of Gitanjali, by Rabindranath Tagore\n\nThis eBook is for the use of anyone anywhere at no cost and with\nalmost no restrictions whatsoever.  You may copy it, give it away...\n"}},"pos":29,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"ac2c5b","input":"import re\nmy_regex = re.compile('Kerryn.{0,10}Phelps') # first 'compile' your regular expression\n\n# Here is the sentence we would like to work with:\nsentence = \"Kerryn Lyndel Phelps is the new member for Wentworth. Most people just call her Kerryn Phelps.\"\n\n# Apply my_regex to our sentence, subbing all matches for the new phrase 'Tony Abbott'\nnew_sentence = my_regex.sub('Tony Abbott', sentence)\n\nprint(f'The old sentence was: \"{sentence}\"')\nprint(f'And the new sentence is: \"{new_sentence}\"')","output":{"0":{"name":"stdout","output_type":"stream","text":"The old sentence was: \"Kerryn Lyndel Phelps is the new member for Wentworth. Most people just call her Kerryn Phelps.\"\nAnd the new sentence is: \"Tony Abbott is the new member for Wentworth. Most people just call her Tony Abbott.\"\n"}},"pos":31,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"9bfc09","input":"# YOUR CODE HERE\n\nstart_1 = '\\A'   # Find the start of the string\nstart_2 = '.+'   # Match one or more of any character\nstart_3 = '\\*{3}'   # Match the exact phrase '***': i.e. match three asterisks (see hint above)\nstart_4 = ' {0,2}'   # Match 0-2 spaces\nstart_5 = 'START OF'   # Match the exact phrase 'START OF' NB: the licence at the end begins with 'START:'\nstart_6 = '.{0,100}'   # Match 0-100 of any character \nstart_7 = '\\*{3}'   # Match three asterisks again\n\n# END OF YOUR CODE\n\nstart_regex = re.compile(start_1 + start_2 + start_3 + start_4 + start_5 + start_6 + start_7, flags = re.DOTALL)\n\nprint(f'My complete start_regex is: {start_regex.pattern}.\\n')\nprint(f'The metadata of {novel_list[0][\"title\"]} is:\\n\\n {start_regex.search(novel_list[0][\"text\"]).group(0)}')","output":{"0":{"name":"stdout","output_type":"stream","text":"My complete start_regex is: \\A.+\\*{3} {0,2}START OF.{0,100}\\*{3}.\n\nThe metadata of erewhon.txt is:\n\n ï»¿The Project Gutenberg eBook, Erewhon, by Samuel Butler\n\n\nThis eBook is for the use of anyone anywhere at no cost and with\nalmost no restrictions whatsoever.  You may copy it, give it away or\nre-use it under the terms of the Project Gutenberg License included\nwith this eBook or online at www.gutenberg.net\n\n\n\n\n\nTitle: Erewhon\n\nAuthor: Samuel Butler\n\nRelease Date: March 20, 2005  [eBook #1906]\n\nLanguage: English\n\nCharacter set encoding: ISO-646-US (US-ASCII)\n\n\n***START OF THE PROJECT GUTENBERG EBOOK EREWHON***\n"}},"pos":33,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"5c9e8c","input":"# YOUR CODE HERE\n\nend_1 = '\\*{3}'    # Match three asterisks\nend_2 = ' {0,2}'    # Match 0-2 spaces\nend_3 = 'END OF'    # Match the exact phrase 'END OF'\nend_4 = '.+'    # Match one or more of any character\n\n# END OF YOUR CODE\n\nend_regex = re.compile(end_1 + end_2 + end_3 + end_4, flags = re.DOTALL)\n\nprint(f'My complete end_regex is: {end_regex.pattern}.\\n')\nprint(f'The licence of {novel_list[3][\"title\"]} is:\\n\\n {end_regex.search(novel_list[3][\"text\"]).group(0)[0:250]}...\\n\\n\\n...{end_regex.search(novel_list[3][\"text\"]).group(0)[-350:-1]}')","output":{"0":{"name":"stdout","output_type":"stream","text":"My complete end_regex is: \\*{3} {0,2}END OF.+.\n\nThe licence of corinne.txt is:\n\n *** END OF THIS PROJECT GUTENBERG EBOOK CORINNE; OR, ITALY***\n\n***** This file should be named 52077-0.txt or 52077-0.zip *****\nThis and all associated files of various formats will be found in:\n        http://www.gutenberg.org/5/2/0/7/52077/\n\nProduc...\n\n\n...\n\nMost people start at our Web site which has the main PG search\nfacility: www.gutenberg.org\n\nThis Web site includes information about Project Gutenberg-tm,\nincluding how to make donations to the Project Gutenberg Literary\nArchive Foundation, how to help produce our new eBooks, and how to\nsubscribe to our email newsletter to hear about new eBooks.\n"}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"11abe6","input":"for novel in novel_list:\n    text = novel['text'] # get the text of the novel\n    text = start_regex.sub('', text) # clean up the start\n    text = end_regex.sub('', text) # clean up the end\n    novel['text'] = text # replace the old text with the cleaned up text\n\nprint(f'After applying our regexes, the beginning text of {novel_list[5][\"title\"]} is:\\n\\n{novel_list[5][\"text\"][0:300]}...')","output":{"0":{"name":"stdout","output_type":"stream","text":"After applying our regexes, the beginning text of pride_and_prejudice.txt is:\n\n\n\n\n\n\nProduced by Anonymous Volunteers\n\n\n\n\n\nPRIDE AND PREJUDICE\n\nBy Jane Austen\n\n\n\nChapter 1\n\n\nIt is a truth universally acknowledged, that a single man in possession\nof a good fortune, must be in want of a wife.\n\nHowever little known the feelings or views of such a man may be on his\nfirst entering a...\n"}},"pos":37,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"9dafa2","input":"orange = {'colour':'orange','type':'citrus','price':'$0.30'}\nprint(orange['price'])\nprint(orange.keys())","output":{"0":{"name":"stdout","output_type":"stream","text":"$0.30\ndict_keys(['colour', 'type', 'price'])\n"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"cfe69c","input":"from nltk.tokenize import wordpunct_tokenize, regexp_tokenize\n\n# Wordpunct_tokenize splits on puncutation\nexample_1 = wordpunct_tokenize(novel_list[5]['text'])\nprint(f'Example 1: {example_1[5835:5844]}')\n\n# Or you can define your own regex:\nexample_2 = regexp_tokenize(novel_list[5]['text'], pattern = '\\w+')\nprint(f'Example 2: {example_2[5835:5844]}')","output":{"0":{"name":"stdout","output_type":"stream","text":"Example 1: ['just', '_tolerable_', '.â', 'â', 'I', 'beg', 'you', 'would', 'not']\nExample 2: ['not', 'know', 'Jane', 's', 'disposition', 'as', 'you', 'do', 'But']\n"}},"pos":40,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"0ce4c8","input":"for novel in novel_list:\n    novel['tokens'] = wordpunct_tokenize(novel['text'])","pos":42,"type":"cell"}
{"cell_type":"code","exec_count":32,"id":"5a336a","input":"from nltk.text import Text\n\ntext_dict = {}\n\nfor novel in novel_list:\n    title = novel['title']\n    nltk_text_object = Text(novel['tokens'])\n    text_dict[title] = nltk_text_object","pos":46,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"27bd43","input":"text_dict['such_is_life.txt'].concordance('tree')","output":{"0":{"name":"stdout","output_type":"stream","text":"Displaying 25 of 37 matches:\nthere . If that ' s so , it ' s up a tree , straight . The ram - paddick ' s a\nof his wagon ; I hitched Bunyip to a tree , and mounted Fancy , and we cantere\nis pocket !\" \" O , go an ' bark up a tree , you mongrel !\" replied the war - m\n ' feller that watches from behine a tree -- keeps curs like Martin to do his \nnted . One of the fallers had left a tree nearly through when he went to dinne\nwhen he says ' mulga ', he means any tree except pine or currajong . Same ment\n day . Eucalypt , conifer , mimosa ; tree , shrub , heath , in endless diversi\nears , I turned aside to inspect the tree . It was worth the trouble . The pin\nfind a comprehensive allegory in the tree ; but I had scarcely turned away fro\npure gladness of life ; endowed each tree with sympathy , respondent to her ow\nlean - spotted column of the leopard tree , creamy white on slate , from base \nhad seen the man reclining under the tree ; and Rory nodded forgivingly when I\n little boomerangs over the same big tree , and we had been welted an equal nu\nsitting on a log , in the shade of a tree , on the north bank of the river , a\n The mustard seed has become a great tree , but the unclean fowls lodge in its\ne river , with the end fastened to a tree . When you haul the wire up out of t\nou ' ll find the other end tied to a tree on this bank . Very complete rig . A\nked my things in a convenient hollow tree , and started off down the river , f\niced , not fifty yards away , a dead tree of twelve or fifteen tons displaceme\n forward end . In remarking that the tree was ong root , I merely mean to impl\nht rather be viewed as a root with a tree attached than as a tree with a root \n root with a tree attached than as a tree with a root attached . This is the a\nhe timber , I posted myself behind a tree , and waited as patiently as the mos\n in front of the buggy till a second tree offered its friendly cover . Jerry '\nas perfect silence for a minute . My tree was n ' t a large one , and the near\n"}},"pos":48,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"206e44","input":"text_dict['jane_eyre.txt'].common_contexts(['Eyre','Rochester'])","output":{"0":{"name":"stdout","output_type":"stream","text":"jane_; jane_, jane_,\" ._came ._has ._mentioned ._. ._'\n"}},"pos":50,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"7ecf1d","input":"import numpy\nimport matplotlib\n%matplotlib inline\n\ntext_dict['corinne.txt'].dispersion_plot(['imagination','love','Italy','England'])","output":{"0":{"data":{"image/png":"1639f221e6a09a8e31b5644438adcfa19b08c064","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":52,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"6aa8dc","input":"arjuna = {'gender':'M', 'species':'demigod', 'family':'Pandavas', 'profession':'archer'}\n\n# YOUR CODE HERE\narjunas_family = arjuna['family']\n\narjuna_keys = arjuna.keys()\n# END OF YOUR CODE\n\nprint(f'Arjuna belongs to the {arjunas_family}.')\nprint(f'We know the following things about Arjuna: {list(arjuna_keys)}')","output":{"0":{"name":"stdout","output_type":"stream","text":"Arjuna belongs to the Pandavas.\nWe know the following things about Arjuna: ['gender', 'species', 'family', 'profession']\n"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"5ce8f2","input":"fruits = [\n    {'name':'orange','colour':'orange','type':'citrus','price':'$0.30'},\n    {'name':'apple','colour':'red','type':'pome','price':'$0.15'},\n    {'name':'pear','colour':'green','type':'pome','price':'$0.10'},\n    {'name':'bluberry','colour':'dark blue','type':'berry','price':'$0.05'}\n]\n\napple_price = fruits[1]['price'] # the apple is the second fruit in the list\npear_type = fruits[2]['type'] # the pear is the third fruit in the list\n\nprint(f'One apple costs {apple_price}.')\nprint(f'A pear is an example of a {pear_type} fruit.')","output":{"0":{"name":"stdout","output_type":"stream","text":"One apple costs $0.15.\nA pear is an example of a pome fruit.\n"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"d3a602","input":"from pandavas import pandavas","pos":11,"type":"cell"}
{"cell_type":"code","id":"037199","input":"# YOUR CODE HERE\nmy_favourite = {\n    'title': ,\n    'writer': ,\n    # ... add whatever extra key:value pairs you like\n}\n# END OF YOUR CODE\nmy_favourite","pos":17,"type":"cell"}
{"cell_type":"code","id":"6047de","input":"# YOUR CODE HERE\nmy_favourite[ ] = \n# END OF YOUR CODE\nmy_favourite","pos":19,"type":"cell"}
{"cell_type":"code","id":"6e006e","input":"# YOUR CODE HERE\n","pos":54,"type":"cell"}
{"cell_type":"code","id":"86d3fd","input":"# YOUR CODE HERE\n\nresults =      # Create the empty dict\n\nfor novel in novel_list:\n    \n    # First retrieve the name of the novel from the dict\n    novel_title = \n    \n    # Then use the len() function on the novel's tokens to calculate the word count\n    novel_length = \n    \n    # Add it to the results dict (done for you):\n    results[novel_title] = novel_length\n\n# END OF YOUR CODE\n\nfor key, value in results.items():\n    print(f'{key} is {value} words long.\\n')","pos":44,"type":"cell"}
{"cell_type":"markdown","id":"04b6f0","input":"## Section 3: Bringing it all together\n\nNow you know how to create a dict, how to do a for loop and how to add items to an empty list. From the previous session, you know how to import a text file using `open('path/to/file.txt', 'r')` and `.read()`.\n\nArmed with this knowledge, you are going to get a list of file names, loop over them and create a `dict` for each text in the corpus.\n\nThe cell below uses the `listdir()` function from the `os` module to get a list of all the files in the `corpus` folder:","pos":26,"type":"cell"}
{"cell_type":"markdown","id":"0f4fb4","input":"### Exercise 1.1: Extract information from a `dict`\n\nIn the cell below, I have provided you a `dict` containing information about Arjuna, the hero of the great epic poem, *Mahabharata*. Use the `dict` to find out what family Arjuna is from, and use the `.keys()` method to find out what else we know about him.","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"12bdcc","input":"When we ingest our corpus, we will store information about each text in a `dict`. But how will we store information about multiple novels? Well, it is possible to store multiple `dicts` in a single `list`. Execute the cell below to see how this works.","pos":8,"type":"cell"}
{"cell_type":"markdown","id":"208b96","input":"To update a `dict`, simply select which piece of information you would like to change, and then use the 'assignment operator', `=`, to set the new value, e.g.\n\n```\norange['price'] = new_price\n```\n\nIn the next cell, change something about your favourite book or movie, e.g. its title:","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"214107","input":"### Exercise 4.2: Clean away the licence at the end of each file\n\nNow you need to do the same for the licence at the end. This regex is much simpler. You simply need to find the phrase `*** END OF` and all the letters that come after it.","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"3c3003","input":"A `dict` is different. It stores information in `key:value` pairs. You get information out of a dict by referring to a `key`. You can get a list of all the keys in a `dict` by using the `.keys()` method. Execute the cell below to see this in action.","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"3fd925","input":"## Section 1: Using lists and dicts to store data\n\nSo far you have been implementing Python commands one at a time. This will obviously become very tedious if you have to deal with more than two or three texts. What if you want to run a stylometric analysis on all 6 of Jane Austen's novels, or all 32 of Shakespeare's plays, or on a historical corpus of thousands of letters or millions of newspaper articles?\n\nTo work with a corpus, we are going to learn to use two new features of Python: `for` loops, which will allow us to apply code to multiple books at once, and `dicts`, which will allow us to store information about our books in a convenient format.\n\nLet's start with the `dict`. So far you are familiar with one main data type, the `list`. A `list` simply stores a bunch of things in an order, and you can fetch them using the numerical index, as in the cell below:","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"41c01f","input":"# DH Downunder: Distant Reading\n\n## Notebook 2: Large Corpora, Regular Expressions, and the NLTK\n\n**Session 2: Tuesday 4th December, 11:00-12:30**\n\nWelcome back to *Distant Reading*. In this notebook, we will build on your skills in Python and introduce the Natural Language Toolkit, a powerful set of tools for working with textual data.\n\nHopefully you have already installed the Natural Language ToolKit, as instructed in the 'Getting Started' section of this repository. If you installed Python using Anaconda, then you already have the NLTK. If not, then you need to open a new Terminal (Mac) or Command Prompt window (Windows), and type the following:\n```\npython -m pip install --upgrade pip\npip install nltk\n```\nIf you have installed the NLTK, you then need to install some of the data that it uses for its more advanced functions. To do this, run the cell below. It may take a few minutes.","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"51061a","input":"Now you have created two regexs that can find the extraneous text in each file, you can loop over your corpus and clean all your texts, using the same [re.sub()](https://docs.python.org/3.7/library/re.html#re.sub) method as we used above to sub Tony Abbott's name for Kerryn Phelps's. To delete any matches found by the regex, we can simply use `''` as the replacement.\n\nI have written the required code for you. Execute the cell below to do it.","pos":36,"type":"cell"}
{"cell_type":"markdown","id":"57138d","input":"### Exercise 2.2: Use a for-loop to add items to an empty list\n\nNow we are going to learn a common technique for importing and storing data in Python. So far in our for-loops we have simply printed the results so we can see what we have done. But we would ideally like to store the results of our code. To do this, we create an empty list, like so:\n```\nempty_list = []\n```\nand then we can add to it by using the `.append()` method:\n```\nempty_list.append(new_thing)\n```\nThis `.append()` method lets us add a new item to our empty list in each iteration of the for-loop. **NB:** When you use `.append()`, you do not need to use the assignment operator, `=`.\n\nIn the cell below you have two tasks.\n1. Create an empty list.\n2. Loop over `number_list`. Create a new number using a mathematical operation (`+`,`-`,`*`,`/`), and store the new number in the empty list using `.append()`.","pos":24,"type":"cell"}
{"cell_type":"markdown","id":"6150b7","input":"Use this list to find out the `name` and `spouse` of the second Pandava in the list and the fifth Pandava.\n\n*Remember:* Python starts counting from 0, not from 1.\n\n*Hint:* If you're stuck, and want to have a look at the structure of the list, try creating a new cell, and then executing one of these commands:\n\n```python\npandavas\n```\nor\n```python\npandavas[0].keys()\n```","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"62613e","input":"You can easily pull up all examples of a particular word from a text and see their context using the `.concordance()` method:","pos":47,"type":"cell"}
{"cell_type":"markdown","id":"65a69f","input":"That's right. The Pandavas had [interesting marriage practices](https://en.wikipedia.org/wiki/Pandava). ","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"712234","input":"### Exercise 5.2: Play around\n\nYou can find a full list of all the `Text()` methods in [the relevant section of the nltk website](http://www.nltk.org/api/nltk.html#nltk.text.Text). Have a play, see if you can find out anything interesting about your corpus of texts! The cell below is blank: do with it what you like...","pos":53,"type":"cell"}
{"cell_type":"markdown","id":"812804","input":"Let's break down the syntax. The first line tells Python to loop over `my_list`. Since this is a list of numbers, we're going to use the word `number` to refer to each item in the list:\n```\nfor number in my_list:\n```\nYou could use a different word, e.g. `x` or `num` or `supercalafragilisticexpealadocious`. It doesn't matter what you pick, so long as it makes sense to you and you are consistent.\n\nIn order for the `for`-loop to work, the next lines must be indented. Since we have used the word `number` to refer to each item in `my_list`, we must use that word in our code that we are applying to the list. This line of code tells Python to look at the `number` we are up to in the list and add two to it:\n```\n    new_number = number + 2\n```\n\n\n### Exercise 2.1: Use a for-loop to turn a list of strings to lower case\n\nIn the cell below, use a `for`-loop to turn all the upper case words to lower case using the `.lower()` method.","pos":22,"type":"cell"}
{"cell_type":"markdown","id":"818b1c","input":"There is still a bit more cleaning up we could do. There are lots of line breaks that make this text hard to read when printed to the screen, and there is still some extraneous metadata. But there is now far less messy text that might interfere with our analysis, and you now have the tools you need to work out how to clean your own texts in future.","pos":38,"type":"cell"}
{"cell_type":"markdown","id":"831e04","input":"## Section 5: Getting started with the NLTK\n\nThe Python Natural Language Toolkit contains lots of nifty features. One that you will probably particuarly appreciate is its library of different tokenisers:","pos":39,"type":"cell"}
{"cell_type":"markdown","id":"89f940","input":"*Note:* For the next cell, you must have `numpy` and `matplotlib` installed as instructed in the Getting Started.\n\nYou can use the `.dispersion_plot` method to see how words are distributed through a text:","pos":51,"type":"cell"}
{"cell_type":"markdown","id":"99e94f","input":"### Exercise 1.3: Create and update your own `dict`.\n\nYou know now how to get information out of a dict, but how do you create a `dict`, or add new information to a `dict` that already exists? Both of these tasks are easy. To create a `dict`, you use curly braces `{}`, and simply enter the keys and values like so: `{key:value, key:value, key:value}`. You use a colon `:` to join a `key` to a `value`, and commas to seperate different `key:value` pairs from one another.\n\n**NB:** If your `keys` or `values` are words, they must be in inverted commas or quotation marks, e.g. `{'name':'Jane' ... }`. If they are numbers, you should leave the quotation marks off, e.g. `{'age':30}`.\n\nIn the cell below, create a `dict` describing you favourite book or movie:","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"9d9642","input":"Using NLTK's built in functions, it becomes very easy to tokenise your entire corpus:","pos":41,"type":"cell"}
{"cell_type":"markdown","id":"a9ad9c","input":"For a more subtle kind of analysis you can use the `common_contexts()` method. For this method, you must provide a `list` of two or more words, and find their common contexts in the text. An underscore represents any one of the words in the `list` you provide.","pos":49,"type":"cell"}
{"cell_type":"markdown","id":"c19ecd","input":"This is a fairly small corpus of 10 texts. But once you know how to import a corpus of 10 texts, exactly the same code will easily import a corpus of 10,000 or 10,000,000.\n\n### Exercise 3.1: Import the corpus\n\nComplete the code in the for-loop below, so that Python will loop over all the files in the `file_list`, create a dict for each novel, and append it to `novel-list`. Each novel will be a `dict` with two `key:value` pairs, like so:\n```\n{'title':'moby_dick.txt','text':'Chapter 1: Call me Ishmael ...'}\n```\nRemember, to read from a file in Python, you must do the following:\n```\npath = 'path/to/your/file.txt'\nwith open(path, 'r', encoding = 'utf-8') as file:\n    my_var = file.read()\n```","pos":28,"type":"cell"}
{"cell_type":"markdown","id":"c449ec","input":"To look at the word count of a particular novel, just type `results['title.txt']`.\n\nA very useful feature of the NLTK is the `Text()` object. If you convert your texts into a `Text()` object, it becomes very easy to do lots of different kinds of analysis on them.","pos":45,"type":"cell"}
{"cell_type":"markdown","id":"d92b5e","input":"### Exercise 5.1: Find out how long each novel is\n\nComplete the for-loop in the cell below to calculate the word length (i.e. the number of tokens) of each novel in the corpus. Store the results in a `dict` of the following form:\n```\nresults = {\n    'moby_dick.txt':200000,\n    'pride_and_prejudice.txt':100000,\n    etc.\n}\n```","pos":43,"type":"cell"}
{"cell_type":"markdown","id":"f10b91","input":"Let's break down that regular expression:\n\n* `Kerryn`: this matches the exact phrase 'Kerryn', and is case-sensitive (it would not match 'kerryn')\n* `.`: the period is a special wildcard in a regex. It matches any character at all.\n* `{0,10}`: this says, 'look for 0-10 of the preceding character'. Since the preceding character in our regex was `.`, this means that the regex will match the word 'Kerryn', followed by 0-10 of any other character.\n* `Phelps`: this matches the exact phrase 'Phelps', and is case-sensitive.\n\nAll together, the regular expression `Kerryn.{0,10}Phelps` looks for the exact words 'Kerryn' and 'Phelps' seperated by 0-10 of any other character.\n\nNow you are going to create two regular expressions, one that can strip away the boilerplate at the start of a Project Gutenberg ebook, and one that can strip away the boilerplate at the end.\n\nEvery Project Gutenberg ebook begins with some metadata. When the metadata is over, a sentence of the following kind appears:\n```\n*** START OF THE PROJECT GUTENBERG EBOOK JANE EYRE ***\n```\nEvery Project Gutenberg ebook ends with a licence allowing you to use it. You know when the book has ended and the licence has begun because of a sentence like this:\n```\n*** END OF THE PROJECT GUTENBERG EBOOK JANE EYRE ***\n```\n\n### Exercise 4.1: Clean away the metadata at the start of each file\n\nUse the cell below to create your first regex, which will strip away the metadata at the beginning. Some tools you can use:\n\n* `[A-Z]` will match any capital letter\n* `.` will match any character\n* `*` is a special character in a Python regex. To look for actual asterisks, you will need to type `\\*`.\n* `{m,n}` will match the preceding character m-n times. `{n}` will match it exactly n times. *Hint:* if you want to find three of the same character in a row, use `{3}`\n* `+` will match the preceding character 1 or more times.\n* `\\A` matches the start of a string (NB: in our dataset, the text of each novel is a single string)\n* You can match a space by simply typing a space: ` `.\n\nIn the cell below, you can come up with each part of your regex seperately. I will deal with the `re.compile()` part for you.","pos":32,"type":"cell"}
{"cell_type":"markdown","id":"f2a783","input":"### Section 4: Cleaning the data using regular expressions\n\nYou might have noticed that the texts in your corpus begin with very similar words:\n```\nprint(novel_list[5][\"text\"][0:200])\n\nThe Project Gutenberg EBook of Moby Dick; or The Whale, by Herman\nMelville\n\nThis eBook is for the use of anyone anywhere at no cost and with almost\nno restrictions whatsoever.  You may copy it, give\n```\nThey also end with fairly simliar words:\n```\nprint(novel_list[5][\"text\"][-300:-1])\n\nacility:\n\n  http://www.gutenberg.org\n\nThis Web site includes information about Project Gutenberg-tm,\nincluding how to make donations to the Project Gutenberg Literary\nArchive Foundation, how to help produce our new eBooks, and how to\nsubscribe to our email newsletter to hear about new eBooks.\n```\nTo get rid of these words, we can use *regular expressions* or *regexs*. A regular expression is a special kind of search term, that allows you to look for text in a very precise and flexible way. Execute the cell below to see how the regular expression `Kerryn.{0,10}Phelps` can be used to find all examples of the name `Kerryn Phelps` in a sentence, even if her middle name `Lyndel` is used.","pos":30,"type":"cell"}
{"cell_type":"markdown","id":"f2d6fd","input":"### Exercise 1.2: Extract information from a list of dicts\n\nIn the cell below, I have provided you a `list` of all the members of the Pandava family. Execute the cell to import the `list`.","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"f3323f","input":"## Section 2: Using a `for`-loop to import your corpus.\n\nNow you are a master of `lists` and `dicts`, it is time to learn how to use a `for`-loop to import your entire corpus.\n\nThere are different ways to use `for`-loops in Python. In this notebook, we will learn the simplest way, which is to apply a `for`-loop to a list. What a `for`-loop lets you do is apply a piece of code to each item in the list. Execute the cell below to see how this works:","pos":20,"type":"cell"}
{"id":0,"time":1587952024817,"type":"user"}
{"last_load":1587537002693,"type":"file"}