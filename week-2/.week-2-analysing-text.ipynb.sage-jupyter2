{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":83374080},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"fdd471","input":"with open(\"https://your url here\") as file:\n    another_novel = None","pos":71,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"3d3cd9","input":"### BEGIN SOLUTION\nwith open('jane_eyre.txt' , mode='r', errors='ignore') as file:\n    jane_eyre = file.read()\nwith open('such_is_life.txt', mode='r', errors='ignore') as file:\n    such_is_life = file.read()\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"import_novels","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":38,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"e2f747","input":"### BEGIN SOLUTION\nmy_string = 'We slept in what had once been the gymnasium.'\nmy_tokens = my_string.split()\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"tokenise_string","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"00c316","input":"stevens_poem = \"\"\"\nAs the immense dew of Florida\nBrings forth\nThe big-finned palm\nAnd green vine angering for life,\n\nAs the immense dew of Florida\nBrings forth hymn and hymn\nFrom the beholder,\nBeholding all these green sides\nAnd gold sides of green sides,\n\nAnd blessed mornings,\nMeet for the eye of the young alligator,\nAnd lightning colors\nSo, in me, come flinging\nForms, flames, and the flakes of flames.\n\"\"\"","pos":22,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"77a088","input":"### BEGIN SOLUTION\nstevens_lower = stevens_poem.lower()\nstevens_tokens = stevens_lower.split()\nstevens_num_and = stevens_tokens.count(\"and\")\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"from_tokens_to_types","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"2ed76e","input":"### BEGIN HIDDEN TESTS\nassert stevens_lower == stevens_poem.lower()\nassert stevens_tokens == stevens_lower.split()\nassert stevens_num_and == stevens_tokens.count(\"and\")\n### END HIDDEN TESTS\nprint(f'In lower case, the first stanza looks like:\\n{stevens_lower[0:98]}')\nprint(f'The first 10 tokens of the poem are: {stevens_tokens[:10]}\\n')\nprint(f'The word \"and\" appears {stevens_num_and} times in \"Nomad Exquisite\".')","metadata":{"nbgrader":{"grade":true,"grade_id":"from_tokens_to_types_test","locked":true,"points":3,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"In lower case, the first stanza looks like:\n\nas the immense dew of florida\nbrings forth\nthe big-finned palm\nand green vine angering for life,\n\nThe first 10 tokens of the poem are: ['as', 'the', 'immense', 'dew', 'of', 'florida', 'brings', 'forth', 'the', 'big-finned']\n\nThe word \"and\" appears 6 times in \"Nomad Exquisite\".\n"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"53b8ea","input":"# Split the poem into individual lines:\nstevens_lines = None\n\n# Split the poem into seperate stanzas:\nstevens_stanzas = None\n\n# Strip out commas from stevens_lower, split into a list of tokens, then count the number of times 'sides' appears:\nstevens_lower_no_commas = None\nstenves_no_commas_tokens = None\nstevens_n_sides = None","pos":29,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"c4461a","input":"with open('fruits.txt') as file:\n    fruits = file.read()\n\nprint(fruits)","output":{"0":{"name":"stdout","output_type":"stream","text":"plum\ngage\nmarrow\npumpkin\npear\ngrape\n"}},"pos":31,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"2d8597","input":"print(fruits)","output":{"0":{"name":"stdout","output_type":"stream","text":"plum\ngage\nmarrow\npumpkin\npear\ngrape\n"}},"pos":33,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"5ada40","input":"file.read()","output":{"0":{"ename":"ValueError","evalue":"I/O operation on closed file.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f3fc120c03c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."]}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"680830","input":"jane_eyre_tokens = jane_eyre.lower().split()\nsuch_is_life_tokens = such_is_life.lower().split()","pos":41,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"8431ae","input":"### BEGIN HIDDEN TESTS\nassert isinstance(my_string, str)\nassert isinstance(my_tokens, list)\nassert my_tokens == my_string.split()\n### END HIDDEN TESTS\nprint(f'Your string before tokenisation: {my_string}')\nprint(f'Your string after tokenisation: {my_tokens}')","metadata":{"nbgrader":{"grade":true,"grade_id":"tokenise_string_tests","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"Your string before tokenisation: We slept in what had once been the gymnasium.\nYour string after tokenisation: ['We', 'slept', 'in', 'what', 'had', 'once', 'been', 'the', 'gymnasium.']\n"}},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"d4db79","input":"### BEGIN HIDDEN TESTS\nassert isinstance(jane_eyre, str)\nassert isinstance(such_is_life, str)\nassert file.errors == 'ignore'\nassert file.mode == 'r'\n### END HIDDEN TESTS\nprint(f'jane_eyre is a {type(jane_eyre).__name__} object {len(jane_eyre):,} characters long.')\nprint(f'such_is_life is a {type(such_is_life).__name__} object {len(such_is_life):,} characters long.')","metadata":{"nbgrader":{"grade":true,"grade_id":"import_novels_tests","locked":true,"points":4,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"jane_eyre is a str object 1,049,267 characters long.\nsuch_is_life is a str object 922,650 characters long.\n"}},"pos":39,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"3326c4","input":"### BEGIN SOLUTION\n# Analyse Jane Eyre\njane_eyre_word_count = len(jane_eyre_tokens)\njane_eyre_types = set(jane_eyre_tokens)\njane_eyre_vocab = len(jane_eyre_types)\n# Analyse Such is Life\nsuch_is_life_word_count = len(such_is_life_tokens)\nsuch_is_life_types = set(such_is_life_tokens)\nsuch_is_life_vocab = len(such_is_life_types)\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"vocab_analysis","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":43,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"dce642","input":"### BEGIN HIDDEN TESTS\nassert jane_eyre_word_count == len(jane_eyre_tokens)\nassert jane_eyre_types == set(jane_eyre_tokens)\nassert jane_eyre_vocab == len(jane_eyre_types)\nassert such_is_life_word_count == len(such_is_life_tokens)\nassert such_is_life_types == set(such_is_life_tokens)\nassert such_is_life_vocab == len(such_is_life_types)\n### END HIDDEN TESTS\nprint(f'\"Jane Eyre\" is {jane_eyre_word_count:,} words long, and has a vocabulary of {jane_eyre_vocab:,}.')\nprint(f'\"Such is Life\" is {such_is_life_word_count:,} words long, and has a vocabulary of {such_is_life_vocab:,}.')","metadata":{"nbgrader":{"grade":true,"grade_id":"vocab_analysis_tests","locked":true,"points":4,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"\"Jane Eyre\" is 188,455 words long, and has a vocabulary of 27,088.\n\"Such is Life\" is 159,602 words long, and has a vocabulary of 28,313.\n"}},"pos":44,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"f6a456","input":"jane_eyre_L = None\nsuch_is_life_L = None","pos":47,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"c52387","input":"plt","metadata":{"nbgrader":{"grade":true,"grade_id":"import_matplotlib_test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"data":{"text/plain":"<module 'matplotlib.pyplot' from '/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py'>"},"exec_count":24,"output_type":"execute_result"}},"pos":52,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"03f26f","input":"a_list_of_numbers = [7,22,3,81,999,0,10]\na_list_of_numbers[1]","output":{"0":{"data":{"text/plain":"22"},"exec_count":3,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"5973db","input":"### BEGIN SOLUTION\nbronte_he = jane_eyre_tokens.count('he')\nbronte_she = jane_eyre_tokens.count('she')\nfurphy_he = such_is_life_tokens.count('he')\nfurphy_she = such_is_life_tokens.count('she')\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"gender_counts","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":59,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"d763b8","input":"### BEGIN HIDDEN TESTS\nassert bronte_he == jane_eyre_tokens.count('he')\nassert bronte_she == jane_eyre_tokens.count('she')\nassert furphy_he == such_is_life_tokens.count('he')\nassert furphy_she == such_is_life_tokens.count('she')\n### END HIDDEN TESTS\nprint(f'Charlotte BrontÃ« uses the word \"he\" {bronte_he} times, and \"she\" {bronte_she} times.')\nprint(f'Joseph Furphy uses the word \"he\" {furphy_he} times, and \"she\" {furphy_she} times.')","metadata":{"nbgrader":{"grade":true,"grade_id":"gender_counts_test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"Charlotte BrontÃ« uses the word \"he\" 1749 times, and \"she\" 1321 times.\nJoseph Furphy uses the word \"he\" 1510 times, and \"she\" 267 times.\n"}},"pos":60,"type":"cell"}
{"cell_type":"code","exec_count":38,"id":"fc9ff7","input":"### BEGIN SOLUTION\nx_values = [\"'He' in BrontÃ«\", \"'She' in BrontÃ«\", \"'He' in Furphy\", \"'She' in Furphy\"]\ny_values = [bronte_he, bronte_she, furphy_he, furphy_she]\nplt.bar(x = label_list, height = variable_list)\nplt.title('Furphy\\'s use of gendered pronouns is less balanced.')\nplt.ylabel('Number of times word appears')\nplt.show()\n### END SOLUTION","metadata":{"nbgrader":{"grade":true,"grade_id":"gender_plot","locked":false,"points":6,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"data":{"image/png":"abd9e996509824ca11ecce704aeca7c78d4b83f1","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":38,"metadata":{"image/png":{"height":426,"width":730},"needs_background":"light"},"output_type":"execute_result"}},"pos":63,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"4505f7","input":"a_list_of_numbers[-1]","output":{"0":{"data":{"text/plain":"10"},"exec_count":4,"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"bcd63c","input":"### BEGIN SOLUTION\nfrom matplotlib import pyplot as plt\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"import_matplotlib","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":51,"type":"cell"}
{"cell_type":"code","exec_count":40,"id":"a48b9c","input":"### BEGIN SOLUTION\nbronte_he_relative = bronte_he/jane_eyre_word_count*1000\nbronte_she_relative = bronte_she/jane_eyre_word_count*1000\nfurphy_he_relative = furphy_he/such_is_life_word_count*1000\nfurphy_she_relative = furphy_she/such_is_life_word_count*1000\ny_values_relative = [bronte_he_relative, bronte_she_relative, furphy_he_relative, furphy_she_relative]\nplt.bar(label_list, relative_variable_list)\nplt.title('Furphy still doesn\\'t look very woke')\nplt.ylabel('Wokeness (measured in words per 1000)')\nplt.show()\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"relative_frequencies","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"data":{"image/png":"358464ee15a7b57e80ab9f71270c8842b1de3189","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":40,"metadata":{"image/png":{"height":426,"width":710},"needs_background":"light"},"output_type":"execute_result"}},"pos":66,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"9c6fdc","input":"a_list_of_numbers[0:2]","output":{"0":{"data":{"text/plain":"[7, 22]"},"exec_count":5,"output_type":"execute_result"}},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"dd8ad2","input":"x = [1,2,3,4,5,6,7,8,9,10,11,12]\ny = [1,4,9,16,25,36,49,64,81,100,121,144]\n\nplt.plot(x, y)\nplt.title(\"A witty title\")\nplt.xlabel(\"A series of numbers\")\nplt.ylabel(\"Those numbers squared\")\nplt.show()","output":{"0":{"data":{"image/png":"0359d1aa903775c6a0ca5625723072d1e0efda00","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":5,"metadata":{"image/png":{"height":440,"width":723},"needs_background":"light"},"output_type":"execute_result"}},"pos":56,"type":"cell"}
{"cell_type":"code","exec_count":51,"id":"0ecdc7","input":"### BEGIN HIDDEN TESTS\nassert bronte_he_relative == bronte_he/jane_eyre_word_count*1000\nassert bronte_she_relative == bronte_she/jane_eyre_word_count*1000\nassert furphy_he_relative == furphy_he/such_is_life_word_count*1000\nassert furphy_she_relative == furphy_she/such_is_life_word_count*1000\n### END HIDDEN TESTS\nprint(f'Relative frequency of `he` in \"Jane Eyre\": {bronte_he_relative:.2f} per 1000 words')\nprint(f'Relative frequency of `she` in \"Jane Eyre\": {bronte_she_relative:.2f} per 1000 words')\nprint(f'Relative frequency of `he` in \"Such is Life\": {furphy_he_relative:.2f} per 1000 words')\nprint(f'Relative frequency of `she` in \"Such is Life\": {furphy_she_relative:.2f} per 1000 words')","metadata":{"nbgrader":{"grade":true,"grade_id":"relative_frequency_tests","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"Relative frequency of `he` in \"Jane Eyre\": 9.28 per 1000 words\nRelative frequency of `she` in \"Jane Eyre\": 7.01 per 1000 words\nRelative frequency of `he` in \"Such is Life\": 9.46 per 1000 words\nRelative frequency of `she` in \"Such is Life\": 1.67 per 1000 words\n"}},"pos":67,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"2cdd57","input":"a_list_of_numbers[5:]","output":{"0":{"data":{"text/plain":"[0, 10]"},"exec_count":6,"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"f17adc","input":"### BEGIN SOLUTION\nfirst_word = my_tokens[0]\npenultimate_word = my_tokens[-2]\nsecond_and_third_words = my_tokens[1:3]\n### END SOLUTION","metadata":{"nbgrader":{"grade":false,"grade_id":"list_indexing","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"826b35","input":"### BEGIN HIDDEN TESTS\nassert first_word == my_tokens[0]\nassert penultimate_word == my_tokens[-2]\nassert second_and_third_words == my_tokens[1:3]\n### END HIDDEN TESTS\nprint(f'My sentence is: {my_string}')\nprint(f'The first word is: \"{first_word}\".')\nprint(f'The penultimate word is: \"{penultimate_word}\".')\nprint(f'The second and third words are: {second_and_third_words}.')","metadata":{"nbgrader":{"grade":true,"grade_id":"list_indexing_tests","locked":true,"points":2,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"My sentence is: We slept in what had once been the gymnasium.\nThe first word is: \"We\".\nThe penultimate word is: \"the\".\nThe second and third words are: ['slept', 'in'].\n"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"6fe948","input":"'Enterprise' == 'enterprise'","output":{"0":{"data":{"text/plain":"False"},"exec_count":9,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"markdown","id":"0616fa","input":"Expected output (with your example text):\n```\nMy sentence is: We slept in what had once been the gymnasium.\nThe first word is: \"We\".\nThe penultimate word is: \"the\".\nThe second and third words are: ['slept', 'in'].\n```","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"0657f3","input":"This code has opened the file `fruits.txt`, which is in the same folder as this notebook, and created a new variable called `fruits`. This variable persists even after we have left the `with` statement:","pos":32,"type":"cell"}
{"cell_type":"markdown","id":"1254bd","input":"### Assignment 2.6: Who has the larger vocabulary?\n\n*Jane Eyre* is famous for its focus on a single developing mind, and its intense emotional narrative. *Such is Life* is famous for its witty allusions, pretentious irony and use of dialect. Hopefully we should be able to detect some of these differences between the novels.\n\nYour task:\n1. **Use the `len()` function to calculate the word count of each novel:** If you call `len()` on a `list` of tokens, it will tell you how many tokens are in the list. [Here is the documentation](https://docs.python.org/3/library/functions.html#len). Store the results in variables called `jane_eyre_word_count` and `such_is_life_word_count`.\n2. **Use the `set()` function to extract each novel's unique types:** [Here is the documentation](https://docs.python.org/3/library/functions.html#set). This function creates a `set` object, [which is a bit like a list, but is unordered and each item in the set must be unique](https://docs.python.org/3/tutorial/datastructures.html#sets). Store the results in variables called `jane_eyre_types` and `such_is_life_types`.\n3. **Use the `len()` function again on each `set` of types to calculate the vocabulary:** If you use `len()` on a `set` of types, it will tell you how many different types are in the set.  Store the results in variables called `jane_eyre_vocab` and `such_is_life_vocab`.","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"13212c","input":"### Assignment 2.1: Tokenise a string\n\nThe first step in text analysis is to tokenise the text. In Python, as in other programming langauges, a string is treated as an unbroken series of characters. In this form it is very difficult to carry out any sort of useful digital analysis. Once you have split a string into tokens, however, it becomes possible to start analysing the distribution of individual words, and things start to get interesting.\n\nIn Week 1 we covered **methods**, and we saw that the `str` object has a useful method called `.join()`. There are many other [useful string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) you will get to know if you spend time analysing text in Python. The one we need now is [.split()](https://docs.python.org/3/library/stdtypes.html#str.split).\n\nYour task:\n\n1. Create a variable called `my_string`, and assign it a sentence or two of text. If you need inspiration, you can try [one of these famous final sentences](https://www.washingtonpost.com/graphics/2019/entertainment/books/best-last-lines/).\n2. Use the `.split()` method to split `my_string` into tokens, and save the result in a variable called `my_tokens`.","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"19484a","input":"## Section 3: Graphing gendered language using `pyplot`\n\nNow that you have converted each novel into a list of words, you can begin to do some basic analysis. Charlotte BrontÃ« is one of the great feminist novelists of the nineteenth century, while Joseph Furphy is more famous for his democratic nationalism. Both suffered from typical nineteenth-century attitudes towards race. Can we find any evidence of this using basic distant reading?\n\nIn this part of the notebook, we are going to use the `pyplot` module from the package `matplotlib`. As explained last week, `matplotlib` is not packaged with Python itself. If you install Python on your own laptop, you may need to install `matplotlib` separately. Here in CoCalc, however, it comes pre-installed. It is Python's standard plotting library, and knowing how to use it is an extremely useful skill in many domains.","pos":49,"type":"cell"}
{"cell_type":"markdown","id":"1b75bf","input":"You can make [many kinds of beautiful graph](https://matplotlib.org/gallery.html) using `matplotlib`. For your first go at using the software, however, you are going to make a simple bar chart.\n\n`matplotlib` makes strong use of Python's object-oriented programming paradigm. The basic pattern is to make repeated calls to the `plt` object, adding all the data and formatting to your graph that you want. Then, when the `plt` object is ready, you use the `plt.show()` method, which makes your plot appear:","pos":54,"type":"cell"}
{"cell_type":"markdown","id":"1d68d0","input":"### Assignment 2.5: Import the two novels\n\nYour first exercise is to use open to find the novels and read in the text. The novels are stored in the files `jane_eyre.txt` and `such_is_life.txt`, which are in the same folder as this notebook.\n* **Use `with` statements** You will need to use two `with` statements, one for each novel. Use \"`as file`\" both times.\n* **Use `open()` with the correct parameters:** In the example, we used `open()` with only one parameter. Let's play it safe this time. Let's use `mode='r'` so that Python knows we only want to *read* the file, and `errors='ignore'`, so that it skips any corrupted characters in the file if there are any.\n* **Give the variables the correct names:** When you read in the novels, store *Jane Eyre* in a variable called `jane_eyre` and *Such is Life* in a variable called `such_is_life`.","pos":37,"type":"cell"}
{"cell_type":"markdown","id":"213de9","input":"# Hacking the Humanities Week 2: Analysing Text\n\nNow you are a master of Python and of Jupyter notebooks, it is time to start working with some text data.\n\nFrom a computer's perspective, a text is simply a string of characters: `\"We slept in what had once been the gymnasium.\"` This week, we will learn how to take a string of charactrs, and transform it so a computer can find interesting patterns in it.","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"2a9afe","input":"Expected output:\n```\nCharlotte BrontÃ« uses the word \"he\" 1749 times, and \"she\" 1321 times.\nJoseph Furphy uses the word \"he\" 1510 times, and \"she\" 267 times.\n```","pos":61,"type":"cell"}
{"cell_type":"markdown","id":"2f425d","input":"Expected output (with your chosen sentence or sentences):\n```\nYour string before tokenisation: We slept in what had once been the gymnasium.\nYour string after tokenisation: ['We', 'slept', 'in', 'what', 'had', 'once', 'been', 'the', 'gymnasium.']\n```","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"2fd3c6","input":"### Assignment 2.11\n\nPerhaps you can already see some thought-provoking data just using the text output. It isn't always necessary to use a graphâsometimes the numbers alone can tell a vivid story. But for the sake of practice, let's turn these numbers into a bar graph.\n\nLike a line graph, a bar graph needs two pieces of data: on the x-axis, a list of labels telling us what each column represents, and on the y-axis, a list of numbers telling us how high each column is.\n\nYour task:\n1. **Prepare your y-data:** Put your four variables, `bronte_he`, `bronte_she`, `furphy_he` and `furphy_she` into a `list` called `y_values`. You can create a list out of variables like so: `my_list = [variable_1, variable_2, ... etc.]`\n2. **Prepare your x-axis column labels:** On a bar graph, it is useful to have individual labels for each bar, showing exactly which category is represented by which one. Create a list called `x_values`, which should contain four strings, each one labelling a different column. **NB:** Make sure that these labels are in the same order as the values in `y_values`.\n3. **Add the data to your plot:** Use `plt.bar()` to create a bar plot. It expects at least two parameters, the values for x then y.\n4. **Add a title and y-axis label to your plot:** Give your plot a title, and label the y-axis using the functions `plt.title()` and `plt.ylabel()`.\n5. **Show your plot:** After you have prepared your plot, reveal it with `plt.show()`.","pos":62,"type":"cell"}
{"cell_type":"markdown","id":"39f9d2","input":"Expected output:\n```\n<module 'matplotlib.pyplot' from '/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py'>\n```","pos":53,"type":"cell"}
{"cell_type":"markdown","id":"44b2cf","input":"### Assignment 2.3: Preprocess a string and count a particular type\n\nFor this assignment, you are going to analyse Wallace Stevens' poem *Nomad Exquisite*. Here it is, as a single string of characters:","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"45d96c","input":"Now for your first substantial piece of distant reading, you are going to compare gendered language in BrontÃ«'s *Jane Eyre* and Furphy's *Such is Life*. First we are going to extract some key statistics from the novels, and then plot them in a bar chart so they are easy to see.","pos":57,"type":"cell"}
{"cell_type":"markdown","id":"4723c5","input":"### Assignment 2.8\n\nThis is a quick revision assignment. Thinking back to **Week 1**, can you import the `pyplot` module from `matplotlib`, and give it the nickname `plt`?","pos":50,"type":"cell"}
{"cell_type":"markdown","id":"509800","input":"### Assignment 2.10\n\nFirst you are going to count the frequency of the words `\"he\"` and `\"she\"` in the two novels. You already have lower-case, tokenised versions of the novels called `jane_eyre_tokens` and `such_is_life_tokens`. (If your session has timed out, simply click <kbd>Validate</kbd> above, and all the preceding cells will be executed for you, restoring the variables.)\n\nYour task: create four variables, `bronte_he`, `bronte_she`, `furphy_he` and `furphy_she`, which record the count for each of the relevant words in the relevant novel.","pos":58,"type":"cell"}
{"cell_type":"markdown","id":"51635a","input":"### Assignment 2.12: Working with relative frequencies\n\nOf course, this comparison could be unfair, because *Such is Life* has fewer words that *Jane Eyre*. It would therefore be better to base our analysis on the [relative frequency](https://en.wikipedia.org/wiki/Frequency_%28statistics%29).\n\nTo calculate the relative frequency, divide the number of `\"he\"`s or `\"she\"`s by the total number of words in each novel. If you recall the **operators** we studied last week, [you will remember which symbols you can use for division and multiplication](https://docs.python.org/3/tutorial/introduction.html#numbers). In computational linguistics, it is standard to talk about word frequency per 1000 words, so you should multiply the result by 1000. Here is the formula:\n\n$$relative frequency = \\frac{frequency\\ of\\ word}{total\\ words} \\times 1000 $$\n\nYour task:\n* **Divide the `\"he\"`s and `\"she\"`s by the total word count for each novel:** Multiply your results by `1000`, so that the frequencies are expressed in 'frequency per 1000 words'. Save the results in new variables called `bronte_he_relative`, `bronte_she_relative`, `furphy_he_relative` and `furphy_she_relative`.\n* **Reproduce your graph with the relative frequencies insteaad:** You can copy and paste your code from above. You will just need to replace `y_values` with a new variable called `y_values_relative`, and you might like to change the y-axis label.\n\n[You will only be marked on the first part of the task.]","pos":65,"type":"cell"}
{"cell_type":"markdown","id":"528d16","input":"Expected output:\n```\njane_eyre is a str object 1,049,267 characters long.\nsuch_is_life is a str object 922,650 characters long.\n```\n\nNow we have loaded the two novels into memory, we can start to do some more interesting analysis. To start off, we can try to get a sense of the different ways Charlotte BrontÃ« and Joseph Furphy use the English language. How long is each novel, and which novelist uses the larger vocabulary?\n\nExecute the cell below to put the novels into lowercase and tokenise them. You can see how we can use 'method chaining' to make our code more concise.","pos":40,"type":"cell"}
{"cell_type":"markdown","id":"551332","input":"### Assignment 2.2: Indexing and slicing `my_tokens`\n\nFor this assignment, you are going to practise indexing and slicing your `my_tokens` list from above. To complete the task, you need to create three variables:\n\n1. A variable called `first_word`, which contains the first word of `my_tokens`.\n2. A variable called `penultimate_word`, which contains the second-last word.\n3. A variable called `second_and_third_words`, which contains the second and third words.","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"56041f","input":"## Conclusion\n\nYou now have some of the key skills required to be a text analyst in Python. You can:\n* Tokenise a string\n* Pre-process the data for analysis, by removing capital letters\n* Import text from a file\n* Analyse word frequencies\n\nHopefully you have also started to think a bit more deeply about how the linguistic structure of a text is related to its meaning. Perhaps the relatives frequencies of `he` and `she` in *Jane Eyre* have something to do with its first-person perspective. And what meaning should we attach to gendered pronouns in *Such is Life*, a famously queer novel wih where women are often mistaken for men?\n\nNext week you will extend your skills in text analysis, and deepen your knowledge of Python itself. You will go deeper into data structures, learning some of the ins and outs of `list`s and `dict`s. You will learn more about \"control flow\", which lets you write complex programs using only a few lines of code. You will learn to do more advanced kinds of tokenisation and pre-processing using regular expressions. And you will apply these skills so that you can analyse many texts at once, without needing to clutter your program with lots of different variables.","pos":69,"type":"cell"}
{"cell_type":"markdown","id":"7c2bee","input":"As you can see, if you ask for items `[0:2]`, Python will return the '0th' item and the '1st' item, stopping just before the '2nd' item. This is probably not the behaviour you expect, but it does start to make sense when you start to write more complex Python programs.\n\nWhat do you think the following will do?","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"7e6dcc","input":"Expected output:\n```\nIn lower case, the first stanza looks like:\n\nas the immense dew of florida\nbrings forth\nthe big-finned palm\nand green vine angering for life,\n\nThe first 10 tokens of the poem are: ['as', 'the', 'immense', 'dew', 'of', 'florida', 'brings', 'forth', 'the', 'big-finned']\n\nThe word \"and\" appears 6 times in \"Nomad Exquisite\".\n```","pos":26,"type":"cell"}
{"cell_type":"markdown","id":"86888e","input":"Now that you have tokenised your sentence, it is in the form of a `list`. With your words in a `list`, you are now able to access them individually, allowing you to count and manipulate them as you please.\n\nOne of the most basic and useful operations you can perform on a list is `indexing`. Using indexing, you can inspect the contents of a list, looking at a particular item in the list, or a particular range of items. If your `list` only has a few items, you can of course easily print it to the screen. But once you start analysing entire poems, plays, novels or other books, your `lists` may get too long to display on screen. To know what your `list` looks like, you will need to be able to dip in and take a look.\n\nTo 'index into' a `list`, you simply use square brackets after the list, and type in the number for the item you want:","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"987f50","input":"### Extension 2.13: Try out your analysis on some other novels\n\nYou now have a wide range of useful text analysis skills, and have the ability to import any textual data you like.\n\nFor this extension activity, you can try downloading other texts directly into Python, and playing around with some of the text analysis techniques you already know. You might like to analyse gendered language, by looking at the relative frequencies of gender pronouns: there are some we have overlooked, such as *her*, *him* and *his*. You could think about other sorts of words you are interested in too.\n\nYou could also try using the `Text()` object from the **Natural Language Toolkit**, which you had a play with last week. Remember, you will need to `import` the `Text` object from `nltk.text`. To create a `Text`, you need to provide the constructor with a list of tokens â luckily you now know how to tokenise a string!\n\nTo get another book from Project Gutenberg, you can use the `open()` function on the url to the text file. For instance, https://www.gutenberg.org/files/41445/41445-0.txt is the url to the text file of *Frankenstein*. If you want to `open()` a novel directly from a url, make sure that the url ends with \"`.txt`\".","pos":70,"type":"cell"}
{"cell_type":"markdown","id":"9d77bc","input":"## Section 1: Types and Tokens\n\nThe most important distinction in text analysis is the distinction between **types** and **tokens**:\n* A **type** is a unique word with a particular sense, as it appears in the dictionary, e.g. \"dune\", meaning \"mound of sand\".\n* A **token** is a particular word in a text, e.g. the 10th word of Aphra Behn's *The Rover*, which happens to be \"different\".\n\nHere is an example. Take these two sentences from Alexis Wright's *[Carpentaria](https://en.wikipedia.org/wiki/Carpentaria_%28novel%29)*:\n\n```\nThe single shrill cry of a windswept bird startled Will Phantom and he stopped dead in his tracks just to listen to it. The poor bird cried continuously as it was pushed further away in sheets of misty rain.\n```\n\nThis sentence contains 39 tokens, but only 33 types This is because six of the types appear twice: `\"bird\"`, `\"in\"`, `\"it\"`, `\"of\"`, `\"the\"`, and `\"to\"`.","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"9e424c","input":"As you can see, Python, like many other programming languages, counts from `0`. If you type `my_list[1]`, you will therefore retrieve the second item.\n\nYou can also count from the *end* of a list using negative numbers. There is no such thing as `-0`, so if you want the final word in a list, you use `-1`:","pos":8,"type":"cell"}
{"cell_type":"markdown","id":"9eb97e","input":"Expected output:\n\n<img src=\"week-2-figure-1.png\" width=\"730\" height=\"426\">","pos":64,"type":"cell"}
{"cell_type":"markdown","id":"a9299f","input":"You can retrieve a range of items using a colon, `:`. This is called 'slicing' rather than 'indexing'.","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"c69707","input":"But after the `with` statement is finished, the 'context' is exited, and the `file` variable is closed:","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"cc4949","input":"To complete this task, you will consult Python's [string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) page and its [list methods](https://docs.python.org/3/tutorial/datastructures.html) page. Your task is threefold:\n1. **Put the supplied string into lower case:** Visit the [string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) page of the Python documentation and find a method like `.split()` that will put all the characters in lower case. Then create a variable called `stevens_lower`, and save the lower-case version of the poem there.\n2. **Tokenise the string**: Split `stevens_lower` into tokens and save it as a variable called `stevens_tokens`.\n2. **Count the number of times `\"and\"` appears in the poem:** Visit the [list methods](https://docs.python.org/3/tutorial/datastructures.html) page of the Python documentation and find a method that lets you count items in a list. Count the number of times `\"and\"` appears in the poem, and store the result in a variable called `stevens_num_and`.","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"cc7694","input":"One issue with lexical density is that the score tends to decrease the longer a text is. Even a freakish author with a vocabulary of 100,000 words would have a low score if they wrote a 900,000-word novel like *Clarissa* or *The Story of the Stone*. How would you address that problem?","pos":48,"type":"cell"}
{"cell_type":"markdown","id":"ce32e6","input":"Expected output:\n```\n\"Jane Eyre\" is 188,455 words long, and has a vocabulary of 27,088.\n\"Such is Life\" is 159,602 words long, and has a vocabulary of 28,313.\n```","pos":45,"type":"cell"}
{"cell_type":"markdown","id":"d2769f","input":"Expected output:\n\n<img src=\"week-2-figure-2.png\" width=\"730\" height=\"426\">\n\n```\nRelative frequency of `he` in \"Jane Eyre\": 9.28 per 1000 words\nRelative frequency of `she` in \"Jane Eyre\": 7.01 per 1000 words\nRelative frequency of `he` in \"Such is Life\": 9.46 per 1000 words\nRelative frequency of `she` in \"Such is Life\": 1.67 per 1000 words\n```","pos":68,"type":"cell"}
{"cell_type":"markdown","id":"d2a40c","input":"Sometimes capital letters matter, of course. 'Rose' is a girl's name, whereas 'rose' is the name of a flower. And of course it might be relevant which words a writer uses to begin a sentence or a line of poetry, two common places where letters are capitalised. But for many tasks, capital letters get in the way.","pos":20,"type":"cell"}
{"cell_type":"markdown","id":"de37ab","input":"If we had not put the poem in lower case, Python would have only found `\"and\"` once, because it would have overlooked the capitalised `\"And\"`s at the beginning of lines 4, 9, 10 and 12. If you play around with the data, you will quickly discover other problems. For instance, if you try to count the words `\"beholder\"` or `\"big\"`, you will get an answer of `0`. This is because the computer thinks that `\"beholder,\"` is different to `\"beholder\"`, and that `\"big-finned\"` is a single word.\n\nNext week, in **Analysing Corpora**, we will learn how to use *regular expressions*, and the tokenisation functions provided by the Natural Language Toolkit. With these additional tools, you will be able to deal with punctuation and other similar issues more cleverly.\n\nNonetheless, the `.split()` method does let you change the splitting rule, and deal with some of these issues without the need for addtional functionality. If you want, [have a look at the documentation](https://docs.python.org/3/library/stdtypes.html#str.split), and then try the following extension activity.","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"dfa294","input":"### Extension 2.7: Lexical density\n\nThere is a programming challenge you are likely to encounter sooner or later: you read an interesting article, where a particular technique is described. The author tells you the mathematical formula, but doesn't provide the programming code!\n\nOne common statistic in computational linguistics is '[lexical density](http://en.wikipedia.org/wiki/Lexical_density)'. Here is the formula:\n\n$$L = \\frac{n_{types}}{n_{tokens}}$$\n\nWhere $L$ is the lexical density, $n_{types}$ is the number of distinct types in a particular text, and $n_{tokens}$ is the number of distinct tokens.\n\nPush yourselfâcan you impelement that in Python?","pos":46,"type":"cell"}
{"cell_type":"markdown","id":"e074f5","input":"### Extension 2.4: Experiment with different tokenisations\n\nTrying altering the `sep` parameter of `.split()`, and see if you do the following. For the last exercise you will need to [find another string method](https://docs.python.org/3/library/stdtypes.html#string-methods) that lets you replace characters in a string. To test whether you've succeeded, create a new cell, index or slice your new variables, and `print()` them.","pos":28,"type":"cell"}
{"cell_type":"markdown","id":"e34eb9","input":"## Section 2: Importing data\n\nSo far we have been working with toy examples. Of course, for text analysis to be useful, you need to be able to use it on your research data. In this section we will learn how to download data into Python from a file on your computer. In the extension activity, if you like, you can experiment with downloading data directly from the internet.\n\nIn the folder for this session, I have provided the .txt files of two novels, Charlotte BrontÃ«'s *Jane Eyre* and the Australian classic, *Such is Life* by [Joseph Furphy](http://adb.anu.edu.au/biography/furphy-joseph-6261). These text files are from **[Project Gutenberg](https://gutenberg.org)**. Project Gutenberg has advantages and disadvantages. On the one hand, every text is proof-read by two different humans, so there are very few errors. But on the other hand, the metadata is very patchy: you don't always know which version of a given text you are analysing. For many novels, this is not a problem, but if you are analysing 'collected' or 'complete' editions of a writer's poetry or plays, or if a text exists in multiple quite different versions (e.g. *Frankenstein*, *King Lear* or *Dr Faustus*), this can be more of an issue.\n\nImporting data can be complex, and also to some extent dangerous. When you interact with a file outside Python, you are giving Python the ability to read and write information stored on your machine. Without taking proper care, you might import problematic data into your Python program, or corrupt or overwrite important files on your hard drive.\n\nTo mitigate some of these risks, it is customary in Python to use a [`with` statement](https://docs.python.org/3.8/reference/compound_stmts.html#the-with-statement) whenever you read or write to a file. A `with` statement is a little bit like the `def` and `class` statement we used in **Week 1**. When we use a `def` or `class` statement, we use indentation to indicate which lines of code are 'inside' the function or object, insulating them from the rest of the program. A `with` statement lets you do something similar, by creating a temporary 'context' for some code. The context is exited after the code has been executed:","pos":30,"type":"cell"}
{"cell_type":"markdown","id":"e4b345","input":"### Practice 2.9\n\nHave a look at the code below. Experiment with the `x` and `y` values, and experiment with different formatting options for the plot. You can find thorough documentation for the `pyplot` module [here](https://matplotlib.org/api/pyplot_summary.html), and you might like to have a go with some of the many [examples](https://matplotlib.org/gallery/index.html).","pos":55,"type":"cell"}
{"cell_type":"markdown","id":"ed4648","input":"Now that we have learned how to tokenise text, we need to work out how to get from tokens to types. We know how to find out what the 233rd word of a novel is, but how do we find out how many times a particular author uses the word 'gooseberry'? How could we answer the whether Shakespeare or James Joyce's vocabulary is larger?\n\nWe humans have no trouble making all sorts of interesting comparisons and distinctions between words. Computers have a very hard time. There are two main reasons:\n\n1. Tokens have ambiguous boundaries. Is `\"isn't\"` one token (`\"isn't\"`), or is it two (`[\"is\", \"n't\"]`)?\n2. There is no single agreed set of types. Are `\"isn't\"` and `\"is not\"` the same word? How about `\"isn't\"` and `\"aren't\"`?\n\nThe problem is even harder in [agglutinative languages](https://en.wikipedia.org/wiki/Agglutinative_language). Consider these examples from Swahili:\n* *ninakuhitaji* means 'I need you'Â â *ni-na-ku-hitaji*, 'I-[present tense]-you-need'\n* *mlikihitaji* means 'you guys needed it' â *m-li-ki-hitaji*, 'you (plural)-[past tense]-it-need'\n\nHow many tokens and/or types are we talking about in this case?\n\nAs you get further into text analysis, you will need to decide for yourself what is the right way to divide up tokens, and classify them into types, given the particular problem you are trying to solve. For the following assignment, you are going to solve the simplest and most common tokenisation problem in English: capitalisation. By default, Python is case sensitive:","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"f12ffe","input":"This is good, because it ensures that we won't accidentally leave a connection to a file open, which could cause problems as our programs grow more complex. It is generally advised to keep connections open only when you actually need them.","pos":36,"type":"cell"}
{"id":0,"time":1588896580796,"type":"user"}
{"last_load":1588896579709,"type":"file"}