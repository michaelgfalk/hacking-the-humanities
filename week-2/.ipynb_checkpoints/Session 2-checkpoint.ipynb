{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DH Downunder: Distant Reading\n",
    "\n",
    "## Notebook 2: Large Corpora, Regular Expressions, and the NLTK\n",
    "\n",
    "**Session 2: Tuesday 4th December, 11:00-12:30**\n",
    "\n",
    "Welcome back to *Distant Reading*. In this notebook, we will build on your skills in Python and introduce the Natural Language Toolkit, a powerful set of tools for working with textual data.\n",
    "\n",
    "Hopefully you have already installed the Natural Language ToolKit, as instructed in the 'Getting Started' section of this repository. If you installed Python using Anaconda, then you already have the NLTK. If not, then you need to open a new Terminal (Mac) or Command Prompt window (Windows), and type the following:\n",
    "```\n",
    "python -m pip install --upgrade pip\n",
    "pip install nltk\n",
    "```\n",
    "If you have installed the NLTK, you then need to install some of the data that it uses for its more advanced functions. To do this, run the cell below. It may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Using lists and dicts to store data\n",
    "\n",
    "So far you have been implementing Python commands one at a time. This will obviously become very tedious if you have to deal with more than two or three texts. What if you want to run a stylometric analysis on all 6 of Jane Austen's novels, or all 32 of Shakespeare's plays, or on a historical corpus of thousands of letters or millions of newspaper articles?\n",
    "\n",
    "To work with a corpus, we are going to learn to use two new features of Python: `for` loops, which will allow us to apply code to multiple books at once, and `dicts`, which will allow us to store information about our books in a convenient format.\n",
    "\n",
    "Let's start with the `dict`. So far you are familiar with one main data type, the `list`. A `list` simply stores a bunch of things in an order, and you can fetch them using the numerical index, as in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [7, 8, 9]\n",
    "print(my_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `dict` is different. It stores information in `key:value` pairs. You get information out of a dict by referring to a `key`. You can get a list of all the keys in a `dict` by using the `.keys()` method. Execute the cell below to see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orange = {'colour':'orange','type':'citrus','price':'$0.30'}\n",
    "print(orange['price'])\n",
    "print(orange.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Extract information from a `dict`\n",
    "\n",
    "In the cell below, I have provided you a `dict` containing information about Arjuna, the hero of the great epic poem, *Mahabharata*. Use the `dict` to find out what family Arjuna is from, and use the `.keys()` method to find out what else we know about him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arjuna = {'gender':'M', 'species':'demigod', 'family':'Pandavas', 'profession':'archer'}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "arjunas_family = \n",
    "\n",
    "arjuna_keys = \n",
    "# END OF YOUR CODE\n",
    "\n",
    "print(f'Arjuna belongs to the {arjunas_family}.')\n",
    "print(f'We know the following things about Arjuna: {list(arjuna_keys)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ingest our corpus, we will store information about each text in a `dict`. But how will we store information about multiple novels? Well, it is possible to store multiple `dicts` in a single `list`. Execute the cell below to see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\n",
    "    {'name':'orange','colour':'orange','type':'citrus','price':'$0.30'},\n",
    "    {'name':'apple','colour':'red','type':'pome','price':'$0.15'},\n",
    "    {'name':'pear','colour':'green','type':'pome','price':'$0.10'},\n",
    "    {'name':'bluberry','colour':'dark blue','type':'berry','price':'$0.05'}\n",
    "]\n",
    "\n",
    "apple_price = fruits[1]['price'] # the apple is the second fruit in the list\n",
    "pear_type = fruits[2]['type'] # the pear is the third fruit in the list\n",
    "\n",
    "print(f'One apple costs {apple_price}.')\n",
    "print(f'A pear is an example of a {pear_type} fruit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Extract information from a list of dicts\n",
    "\n",
    "In the cell below, I have provided you a `list` of all the members of the Pandava family. Execute the cell to import the `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandavas import pandavas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this list to find out the `name` and `spouse` of the second Pandava in the list and the fifth Pandava.\n",
    "\n",
    "*Remember:* Python starts counting from 0, not from 1.\n",
    "\n",
    "*Hint:* If you're stuck, and want to have a look at the structure of the list, try creating a new cell, and then executing one of these commands:\n",
    "\n",
    "```python\n",
    "pandavas\n",
    "```\n",
    "or\n",
    "```python\n",
    "pandavas[0].keys()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "second_name = \n",
    "second_spouse = \n",
    "\n",
    "fifth_name = \n",
    "fifth_spouse = \n",
    "\n",
    "num_pandavas = \n",
    "# END OF YOUR CODE\n",
    "\n",
    "print(f'The second-eldest Pandava was {second_name}. He was married to {second_spouse}.')\n",
    "print(f'The fifth Pandava was {fifth_name}. He was married to {fifth_spouse}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right. The Pandavas had [interesting marriage practices](https://en.wikipedia.org/wiki/Pandava). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Create and update your own `dict`.\n",
    "\n",
    "You know now how to get information out of a dict, but how do you create a `dict`, or add new information to a `dict` that already exists? Both of these tasks are easy. To create a `dict`, you use curly braces `{}`, and simply enter the keys and values like so: `{key:value, key:value, key:value}`. You use a colon `:` to join a `key` to a `value`, and commas to seperate different `key:value` pairs from one another.\n",
    "\n",
    "**NB:** If your `keys` or `values` are words, they must be in inverted commas or quotation marks, e.g. `{'name':'Jane' ... }`. If they are numbers, you should leave the quotation marks off, e.g. `{'age':30}`.\n",
    "\n",
    "In the cell below, create a `dict` describing you favourite book or movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "my_favourite = {\n",
    "    'title': ,\n",
    "    'writer': ,\n",
    "    # ... add whatever extra key:value pairs you like\n",
    "}\n",
    "# END OF YOUR CODE\n",
    "my_favourite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update a `dict`, simply select which piece of information you would like to change, and then use the 'assignment operator', `=`, to set the new value, e.g.\n",
    "\n",
    "```\n",
    "orange['price'] = new_price\n",
    "```\n",
    "\n",
    "In the next cell, change something about your favourite book or movie, e.g. its title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "my_favourite[ ] = \n",
    "# END OF YOUR CODE\n",
    "my_favourite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Using a `for`-loop to import your corpus.\n",
    "\n",
    "Now you are a master of `lists` and `dicts`, it is time to learn how to use a `for`-loop to import your entire corpus.\n",
    "\n",
    "There are different ways to use `for`-loops in Python. In this notebook, we will learn the simplest way, which is to apply a `for`-loop to a list. What a `for`-loop lets you do is apply a piece of code to each item in the list. Execute the cell below to see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [7, 12, 84, 6, 0]\n",
    "\n",
    "for number in my_list:\n",
    "    new_number = number + 2\n",
    "    print(f\"The new number is {new_number}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the syntax. The first line tells Python to loop over `my_list`. Since this is a list of numbers, we're going to use the word `number` to refer to each item in the list:\n",
    "```\n",
    "for number in my_list:\n",
    "```\n",
    "You could use a different word, e.g. `x` or `num` or `supercalafragilisticexpealadocious`. It doesn't matter what you pick, so long as it makes sense to you and you are consistent.\n",
    "\n",
    "In order for the `for`-loop to work, the next lines must be indented. Since we have used the word `number` to refer to each item in `my_list`, we must use that word in our code that we are applying to the list. This line of code tells Python to look at the `number` we are up to in the list and add two to it:\n",
    "```\n",
    "    new_number = number + 2\n",
    "```\n",
    "\n",
    "\n",
    "### Exercise 2.1: Use a for-loop to turn a list of strings to lower case\n",
    "\n",
    "In the cell below, use a `for`-loop to turn all the upper case words to lower case using the `.lower()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_case_list = ['THE','CAT','SAT','ON','THE','MAT']\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "for ... in ... :\n",
    "    new_word = \n",
    "    \n",
    "# END OF YOUR CODE\n",
    "    print(f'The new word is {new_word}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Use a for-loop to add items to an empty list\n",
    "\n",
    "Now we are going to learn a common technique for importing and storing data in Python. So far in our for-loops we have simply printed the results so we can see what we have done. But we would ideally like to store the results of our code. To do this, we create an empty list, like so:\n",
    "```\n",
    "empty_list = []\n",
    "```\n",
    "and then we can add to it by using the `.append()` method:\n",
    "```\n",
    "empty_list.append(new_thing)\n",
    "```\n",
    "This `.append()` method lets us add a new item to our empty list in each iteration of the for-loop. **NB:** When you use `.append()`, you do not need to use the assignment operator, `=`.\n",
    "\n",
    "In the cell below you have two tasks.\n",
    "1. Create an empty list.\n",
    "2. Loop over `number_list`. Create a new number using a mathematical operation (`+`,`-`,`*`,`/`), and store the new number in the empty list using `.append()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = [54,77,23,4,90,81]\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "empty_list = \n",
    "\n",
    "# Loop over the empty list:\n",
    "for ... in ... :\n",
    "    # Calculate the new number:\n",
    "    new_number = \n",
    "    # Append it to the empty list:\n",
    "    \n",
    "\n",
    "# END OF YOUR CODE\n",
    "    print(f'New number apppended! The empty_list is now: {empty_list}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Bringing it all together\n",
    "\n",
    "Now you know how to create a dict, how to do a for loop and how to add items to an empty list. From the previous session, you know how to import a text file using `open('path/to/file.txt', 'r')` and `.read()`.\n",
    "\n",
    "Armed with this knowledge, you are going to get a list of file names, loop over them and create a `dict` for each text in the corpus.\n",
    "\n",
    "The cell below uses the `listdir()` function from the `os` module to get a list of all the files in the `corpus` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_list = os.listdir('corpus') # get list of filenames in 'corpus' folder\n",
    "file_list # print the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fairly small corpus of 10 texts. But once you know how to import a corpus of 10 texts, exactly the same code will easily import a corpus of 10,000 or 10,000,000.\n",
    "\n",
    "### Exercise 3.1: Import the corpus\n",
    "\n",
    "Complete the code in the for-loop below, so that Python will loop over all the files in the `file_list`, create a dict for each novel, and append it to `novel-list`. Each novel will be a `dict` with two `key:value` pairs, like so:\n",
    "```\n",
    "{'title':'moby_dick.txt','text':'Chapter 1: Call me Ishmael ...'}\n",
    "```\n",
    "Remember, to read from a file in Python, you must do the following:\n",
    "```\n",
    "path = 'path/to/your/file.txt'\n",
    "with open(path, 'r', encoding = 'utf-8') as file:\n",
    "    my_var = file.read()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "\n",
    "# First create the empty list to store your corpus:\n",
    "novel_list = \n",
    "\n",
    "# Now loop over 'file_list':\n",
    "for ... in ... :\n",
    "    # Create a new dict for the current novel in the list (done for you)\n",
    "    current_novel = {}\n",
    "    \n",
    "    # Set the title to be the file name \n",
    "    current_novel['title'] = \n",
    "    \n",
    "    # Now open the file of the novel.\n",
    "    # First add 'corpus/' to the file name, so that Python knows where to find the file:\n",
    "    file_path = 'corpus/' + \n",
    "    \n",
    "    # Then open the file and read it:\n",
    "    with open(..., 'r', encoding='utf-8') as ...:\n",
    "        # Now the file is open, use the '.read()' method to get the text\n",
    "        current_novel['text'] = \n",
    "    # Finally, append the current novel to the novel_list:\n",
    "    \n",
    "    \n",
    "# END OF YOUR CODE\n",
    "\n",
    "rint(f'Corpus imported. There are {len(novel_list)} novels in the corpus.\\n')\n",
    "print(f'The third novel is {novel_list[2][\"title\"]}. The first 200 characters are:\\n\\n {novel_list[2][\"text\"][0:200]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Cleaning the data using regular expressions\n",
    "\n",
    "You might have noticed that the texts in your corpus begin with very similar words:\n",
    "```\n",
    "print(novel_list[5][\"text\"][0:200])\n",
    "\n",
    "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman\n",
    "Melville\n",
    "\n",
    "This eBook is for the use of anyone anywhere at no cost and with almost\n",
    "no restrictions whatsoever.  You may copy it, give\n",
    "```\n",
    "They also end with fairly simliar words:\n",
    "```\n",
    "print(novel_list[5][\"text\"][-300:-1])\n",
    "\n",
    "acility:\n",
    "\n",
    "  http://www.gutenberg.org\n",
    "\n",
    "This Web site includes information about Project Gutenberg-tm,\n",
    "including how to make donations to the Project Gutenberg Literary\n",
    "Archive Foundation, how to help produce our new eBooks, and how to\n",
    "subscribe to our email newsletter to hear about new eBooks.\n",
    "```\n",
    "To get rid of these words, we can use *regular expressions* or *regexs*. A regular expression is a special kind of search term, that allows you to look for text in a very precise and flexible way. Execute the cell below to see how the regular expression `Kerryn.{0,10}Phelps` can be used to find all examples of the name `Kerryn Phelps` in a sentence, even if her middle name `Lyndel` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "my_regex = re.compile('Kerryn.{0,10}Phelps') # first 'compile' your regular expression\n",
    "\n",
    "# Here is the sentence we would like to work with:\n",
    "sentence = \"Kerryn Lyndel Phelps is the new member for Wentworth. Most people just call her Kerryn Phelps.\"\n",
    "\n",
    "# Apply my_regex to our sentence, subbing all matches for the new phrase 'Tony Abbott'\n",
    "new_sentence = my_regex.sub('Tony Abbott', sentence)\n",
    "\n",
    "print(f'The old sentence was: \"{sentence}\"')\n",
    "print(f'And the new sentence is: \"{new_sentence}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down that regular expression:\n",
    "\n",
    "* `Kerryn`: this matches the exact phrase 'Kerryn', and is case-sensitive (it would not match 'kerryn')\n",
    "* `.`: the period is a special wildcard in a regex. It matches any character at all.\n",
    "* `{0,10}`: this says, 'look for 0-10 of the preceding character'. Since the preceding character in our regex was `.`, this means that the regex will match the word 'Kerryn', followed by 0-10 of any other character.\n",
    "* `Phelps`: this matches the exact phrase 'Phelps', and is case-sensitive.\n",
    "\n",
    "All together, the regular expression `Kerryn.{0,10}Phelps` looks for the exact words 'Kerryn' and 'Phelps' seperated by 0-10 of any other character.\n",
    "\n",
    "Now you are going to create two regular expressions, one that can strip away the boilerplate at the start of a Project Gutenberg ebook, and one that can strip away the boilerplate at the end.\n",
    "\n",
    "Every Project Gutenberg ebook begins with some metadata. When the metadata is over, a sentence of the following kind appears:\n",
    "```\n",
    "*** START OF THE PROJECT GUTENBERG EBOOK JANE EYRE ***\n",
    "```\n",
    "Every Project Gutenberg ebook ends with a licence allowing you to use it. You know when the book has ended and the licence has begun because of a sentence like this:\n",
    "```\n",
    "*** END OF THE PROJECT GUTENBERG EBOOK JANE EYRE ***\n",
    "```\n",
    "\n",
    "### Exercise 4.1: Clean away the metadata at the start of each file\n",
    "\n",
    "Use the cell below to create your first regex, which will strip away the metadata at the beginning. Some tools you can use:\n",
    "\n",
    "* `[A-Z]` will match any capital letter\n",
    "* `.` will match any character\n",
    "* `*` is a special character in a Python regex. To look for actual asterisks, you will need to type `\\*`.\n",
    "* `{m,n}` will match the preceding character m-n times. `{n}` will match it exactly n times. *Hint:* if you want to find three of the same character in a row, use `{3}`\n",
    "* `+` will match the preceding character 1 or more times.\n",
    "* `\\A` matches the start of a string (NB: in our dataset, the text of each novel is a single string)\n",
    "* You can match a space by simply typing a space: ` `.\n",
    "\n",
    "In the cell below, you can come up with each part of your regex seperately. I will deal with the `re.compile()` part for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "start_1 =    # Find the start of the string\n",
    "start_2 =    # Match one or more of any character\n",
    "start_3 =    # Match the exact phrase '***': i.e. match three asterisks (see hint above)\n",
    "start_4 =    # Match 0-2 spaces\n",
    "start_5 =    # Match the exact phrase 'START OF' NB: the licence at the end begins with 'START:'\n",
    "start_6 =    # Match 0-100 of any character \n",
    "start_7 =    # Match three asterisks again\n",
    "\n",
    "# END OF YOUR CODE\n",
    "\n",
    "start_regex = re.compile(start_1 + start_2 + start_3 + start_4 + start_5 + start_6 + start_7, flags = re.DOTALL)\n",
    "\n",
    "print(f'My complete start_regex is: {start_regex.pattern}.\\n')\n",
    "print(f'The metadata of {novel_list[0][\"title\"]} is:\\n\\n {start_regex.search(novel_list[0][\"text\"]).group(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Clean away the licence at the end of each file\n",
    "\n",
    "Now you need to do the same for the licence at the end. This regex is much simpler. You simply need to find the phrase `*** END OF` and all the letters that come after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "end_1 =     # Match three asterisks\n",
    "end_2 =     # Match 0-2 spaces\n",
    "end_3 =     # Match the exact phrase 'END OF'\n",
    "end_4 =     # Match one or more of any character\n",
    "\n",
    "# END OF YOUR CODE\n",
    "\n",
    "end_regex = re.compile(end_1 + end_2 + end_3 + end_4, flags = re.DOTALL)\n",
    "\n",
    "print(f'My complete end_regex is: {end_regex.pattern}.\\n')\n",
    "print(f'The licence of {novel_list[3][\"title\"]} is:\\n\\n {end_regex.search(novel_list[3][\"text\"]).group(0)[0:250]}...\\n\\n\\n...{end_regex.search(novel_list[3][\"text\"]).group(0)[-350:-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have created two regexs that can find the extraneous text in each file, you can loop over your corpus and clean all your texts, using the same [re.sub()](https://docs.python.org/3.7/library/re.html#re.sub) method as we used above to sub Tony Abbott's name for Kerryn Phelps's. To delete any matches found by the regex, we can simply use `''` as the replacement.\n",
    "\n",
    "I have written the required code for you. Execute the cell below to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for novel in novel_list:\n",
    "    text = novel['text'] # get the text of the novel\n",
    "    text = start_regex.sub('', text) # clean up the start\n",
    "    text = end_regex.sub('', text) # clean up the end\n",
    "    novel['text'] = text # replace the old text with the cleaned up text\n",
    "\n",
    "print(f'After applying our regexes, the beginning text of {novel_list[5][\"title\"]} is:\\n\\n{novel_list[5][\"text\"][0:300]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still a bit more cleaning up we could do. There are lots of line breaks that make this text hard to read when printed to the screen, and there is still some extraneous metadata. But there is now far less messy text that might interfere with our analysis, and you now have the tools you need to work out how to clean your own texts in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Getting started with the NLTK\n",
    "\n",
    "The Python Natural Language Toolkit contains lots of nifty features. One that you will probably particuarly appreciate is its library of different tokenisers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize, regexp_tokenize\n",
    "\n",
    "# Wordpunct_tokenize splits on puncutation\n",
    "example_1 = wordpunct_tokenize(novel_list[5]['text'])\n",
    "print(f'Example 1: {example_1[5835:5844]}')\n",
    "\n",
    "# Or you can define your own regex:\n",
    "example_2 = regexp_tokenize(novel_list[5]['text'], pattern = '\\w+')\n",
    "print(f'Example 2: {example_2[5835:5844]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLTK's built in functions, it becomes very easy to tokenise your entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for novel in novel_list:\n",
    "    novel['tokens'] = wordpunct_tokenize(novel['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Find out how long each novel is\n",
    "\n",
    "Complete the for-loop in the cell below to calculate the word length (i.e. the number of tokens) of each novel in the corpus. Store the results in a `dict` of the following form:\n",
    "```\n",
    "results = {\n",
    "    'moby_dick.txt':200000,\n",
    "    'pride_and_prejudice.txt':100000,\n",
    "    etc.\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "results =      # Create the empty dict\n",
    "\n",
    "for novel in novel_list:\n",
    "    \n",
    "    # First retrieve the name of the novel from the dict\n",
    "    novel_title = \n",
    "    \n",
    "    # Then use the len() function on the novel's tokens to calculate the word count\n",
    "    novel_length = \n",
    "    \n",
    "    # Add it to the results dict (done for you):\n",
    "    results[novel_title] = novel_length\n",
    "\n",
    "# END OF YOUR CODE\n",
    "\n",
    "for key, value in results.items():\n",
    "    print(f'{key} is {value} words long.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at the word count of a particular novel, just type `results['title.txt']`.\n",
    "\n",
    "A very useful feature of the NLTK is the `Text()` object. If you convert your texts into a `Text()` object, it becomes very easy to do lots of different kinds of analysis on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text\n",
    "\n",
    "text_dict = {}\n",
    "\n",
    "for novel in novel_list:\n",
    "    title = novel['title']\n",
    "    nltk_text_object = Text(novel['tokens'])\n",
    "    text_dict[title] = nltk_text_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily pull up all examples of a particular word from a text and see their context using the `.concordance()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dict['such_is_life.txt'].concordance('tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more subtle kind of analysis you can use the `common_contexts()` method. For this method, you must provide a `list` of two or more words, and find their common contexts in the text. An underscore represents any one of the words in the `list` you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dict['jane_eyre.txt'].common_contexts(['Eyre','Rochester'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* For the next cell, you must have `numpy` and `matplotlib` installed as instructed in the Getting Started.\n",
    "\n",
    "You can use the `.dispersion_plot` method to see how words are distributed through a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "text_dict['corinne.txt'].dispersion_plot(['imagination','love','Italy','England'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Play around\n",
    "\n",
    "You can find a full list of all the `Text()` methods in [the relevant section of the nltk website](http://www.nltk.org/api/nltk.html#nltk.text.Text). Have a play, see if you can find out anything interesting about your corpus of texts! The cell below is blank: do with it what you like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
